{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# These libraries are for importing the data\n",
    "from astroNN.models import Galaxy10CNN\n",
    "from astroNN.datasets import galaxy10\n",
    "from astroNN.datasets.galaxy10 import galaxy10cls_lookup, galaxy10_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Data\n",
    "images, labels = galaxy10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to 10 categorical classes\n",
    "labels_cat = utils.to_categorical(labels, 10)\n",
    "\n",
    "# Convert to desirable type: float32\n",
    "labels_cat = labels_cat.astype(np.float32)\n",
    "images = images.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image Length:', len(images))\n",
    "print('Image Shape:', images.shape)\n",
    "\n",
    "print('Label Length:', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images)\n",
    "print(labels)\n",
    "print(labels_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slider to browse all of the galaxy images\n",
    "def browse_images(images, labels, categories, size):\n",
    "    images = images[:size]\n",
    "    labels = labels[:size]\n",
    "    n = len(images)\n",
    "    def view_image(i):\n",
    "        plt.imshow(images[i].astype('uint8'), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('Class {}: {} \\n Random Demo images {} of 10'.format(np.argmax(labels_cat[i]), galaxy10cls_lookup(labels_cat[i]), i+1))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    interact(view_image, i=(0,n-1))\n",
    "    \n",
    "unique_cat = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_images(images, labels, unique_cat, size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Bar Plot\n",
    "plt.figure(figsize=(14, 3))\n",
    "\n",
    "y_unique = np.unique(labels)\n",
    "counts = [(labels == i).sum() for i in y_unique]\n",
    "\n",
    "plt.xticks(y_unique,  unique_cat[y_unique])\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, size=20)\n",
    "plt.bar(y_unique, counts)\n",
    "plt.title('Category Count Bar Plot')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(images, labels_cat, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find shape/dimension of training vectors\n",
    "print(train_vectors.shape)\n",
    "\n",
    "# Find shape/dimension of training labels\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the training and testing vectors\n",
    "train_vectors = train_vectors.reshape(train_vectors.shape[0],-1)/255\n",
    "test_vectors = test_vectors.reshape(test_vectors.shape[0],-1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New shape of the traininv vectors\n",
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Sequential Neural Network\n",
    "network = Sequential()\n",
    "network.add(Dense(10, input_dim=14283, activation='relu'))\n",
    "network.add(Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model to the training data\n",
    "start = time.time()\n",
    "history=network.fit(train_vectors, train_labels, epochs=10,  validation_split=0.1)\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the training data to only contain 200 observations\n",
    "random_indices = np.random.choice(16338, size=200, replace=False)\n",
    "\n",
    "tmp_vectors = train_vectors[random_indices, :]\n",
    "tmp_labels = train_labels[random_indices,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch the subset of data to determine best estimators\n",
    "start = time.time()\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='linear', class_weight='balanced'), param_grid)\n",
    "\n",
    "clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary training data to use on the model\n",
    "random_indices = np.random.choice(16338, size=1000, replace=False)\n",
    "\n",
    "act_tmp_vectors = train_vectors[random_indices,:]\n",
    "act_tmp_labels = train_labels[random_indices,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with the entire training set using the best estimators\n",
    "start = time.time()\n",
    "\n",
    "clf = SVC(kernel = 'linear', C = 1000.0, gamma = 0.0001)\n",
    "clf.fit(act_tmp_vectors, act_tmp_labels)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes of the testing data\n",
    "random_indices = np.random.choice(5447, size=333, replace=False)\n",
    "\n",
    "predict_vectors = test_vectors[random_indices,:]\n",
    "true_labels = test_labels[random_indices,0]\n",
    "\n",
    "pred_labels = clf.predict(predict_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network model\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') # creating plots to show loss with increased epochs\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs=range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc') # creating plots to show accuracy with increased epochs\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network.evaluate(test_vectors, test_labels)\n",
    "print('test_acc:', test_acc) # calculating the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Model (SVM)\n",
    "\n",
    "print(\"ACC:\",accuracy_score(true_labels, pred_labels)) # we want to know if this model is more accurate than our artificial neural network\n",
    "print('Confusion Matrix: \\n', confusion_matrix(true_labels, pred_labels)) # we want to see how many false positives and false negatives there are \n",
    "      \n",
    "fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "plt.plot(fpr, tpr, \"x-\")\n",
    "plt.plot([0,1],[0,1],\"k-\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "\n",
    "print(\"AUC\", roc_auc_score(true_labels, pred_labels)) # we want to see the AUC score of the model to see how predictive it is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
